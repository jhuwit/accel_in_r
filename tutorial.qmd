---
title: "Introduction to Accelerometer Data"
author: "John Muschelli and Lily Koffman"
format: 
  revealjs:
    theme: default
    smaller: true
    slide-number: true
    transition: fade
    progress: true
    background: background.png
    logo: images/jhu.png
    css: logo.css
bibliography: references.bib
---

```{r setup, include = FALSE}
library(knitr)
library(hms)
library(lubridate)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Introduction to Accelerometer Data

### Learning Objectives

- Understand the basics of procewssing accelerometer data
- GT3X -> CSV/Activity Counts/Steps
- Open source methods in R
- Many of the methods either have a Python analog
- Lots are R wrapper for Python libraries
- GGIR

::: {.notes}
Speaker notes go here.
:::

---

## What is Accelerometer Data?

- **Sensor that measures acceleration** in 3D space: X/Y/Z
- Typically measured in **g-forces (g)** or **m/sÂ²**
- Sampled at regular(ish) time intervals (e.g., 30Hz, 100Hz)

```plaintext
Timestamp                  X        Y        Z
2025-02-17 12:00:00.0125   0.02     0.98     0.03
2025-02-17 12:00:00.0250   0.04     0.95     0.05
2025-02-17 12:00:00.0375  -0.01     0.99     0.02
```


---

## How Does It Work?

1. Small **MEMS (micro electro mechanical system) accelerometer** inside a wearable device
2. Measures acceleration by detecting **motion and gravitational forces**
3. Outputs time-series data: raw acceleration signals


---

## Wrist-Worn vs. Hip-Worn Accelerometers

| Feature       | Wrist-Worn Devices  | Hip-Worn Devices  |
|--------------|------------------|-----------------|
| Placement    | Worn on wrist    | Attached to belt |
| Compliance   | Higher           | Lower           |
| Activity Types | Captures arm movements | Better for whole-body movement |

---

## Common Data Formats

- **Raw Accelerometer Data** (high-resolution time-series data)
- **Activity Counts** (aggregated over time windows)
- **Wear Time Detection** (non-wear vs. wear periods)
- **Steps** (estimation of a "step")

```{r silly_walks}
#| echo: false
#| height: 400px
knitr::include_graphics(here::here("images/silly_walks.gif"))
```


---

## Example Studies

- **NHANES Accelerometry (CDC)**
- Large-scale population studies using wrist-worn devices
- Released raw data - we released processed version
- **UK Biobank Wearable Data**
- Over 100,000 participants with 7-day wrist accelerometer recordings
- All of US uses FitBit


---

## Technical Stuff: Conda/Environments

- If using Python, you know `conda`
- If using R, Python link using `reticulate` package
- Multiple `conda` environments may be needed
- package/module A needs numpy <= 2.11 and package B needs numpy > 2.30
- "Switching" conda environments **within** a script/session is a hassle

## Brief Package overview


:::: {.columns}

::: {.column width="50%"}

- `read.gt3x` - reads GT3X format [CRAN]()/[GitHub]()
- `agcounts` - on CRAN, wrapper of Python and other uses [CRAN]()/[GitHub]()
- `actilifecounts` - on CRAN, implements Activity Counts native in R [CRAN]()/[GitHub]()
- `agcounter`: direct wrapper of Python code (uses conda), but not on CRAN [CRAN]()/[GitHub]()
- `GGIR` - the firehose of outputs/`GGIRread` - reader [CRAN]()/[GitHub]()
- `actigraph.sleepr` - implements Choi/Troiano wear time methods [CRAN]()/[GitHub]()

:::

::: {.column width="50%"}

- `stepcount` - implements stepcount algorithm from Oxford group [CRAN]()/[GitHub]()
- `walking` - implements other walking/step estimation methods
- `ADEPT` - walking segmentation
- `MIMSunit` - calculates MIMS units
- `acc` - explore accelerometer data
- `accelerometry` - functions for Processing Accelerometer Data 
- `SummarizedActigraphy` - dumping ground for some functions we made


:::

::::

## Data

- Single file `AI15_MOS2D09170398_2017-10-30.gt3x` from [Figshare repository](https://springernature.figshare.com/collections/Upper_limb_activity_of_twenty_myoelectric_prosthesis_users_and_twenty_healthy_anatomically_intact_adults_/4457855) 
- From @upper_limb_figshare, which was released with the publication @chadwell2019upper. 
- Start with GT3X file - ActiGraph format
- We can talk technical aspects of this binary file, but let's just read it in


## Getting Data

```{r download_file, echo = TRUE}
gt3x_file = here::here("data/AI15_MOS2D09170398_2017-10-30.gt3x")
if (!file.exists(gt3x_file)) {
  url = paste0("https://github.com/jhuwit/", 
               "accel_in_r", 
               "/raw/main/",
               "data/AI15_MOS2D09170398_2017-10-30.gt3x")
  curl::curl_download(url = url, destfile = gt3x_file)
}
```

## Read in the data
- Using `read.gt3x::read.gt3x` function
- `asDataFrame` - make it a `data.frame`
- `imputeZeroes` - discuss idle sleep mode

```{r read_file}
library(read.gt3x)
(df = read.gt3x::read.gt3x(path = gt3x_file, 
                           asDataFrame = TRUE, 
                           imputeZeroes = TRUE))
```

::: {.notes}
Idle sleep mode is a battery saving option when enabling and setting up ActiGraph devices.  It's a hassle, don't use it unless you have to.  It causes "gaps" in the GT3X file that are truly missing , but this is an issue with many processing methods (gaps), so you can "impute" zeroes into the data set, which aren't correct either. 
:::

## Where are the subseconds?

`digits.secs` - show a certain number of digits for seconds from time

:::: {.columns}

::: {.column width="50%"}

```{r options}
getOption("digits.secs")
options(digits.secs = 3)
df
```

::: 

::: {.column width="50%"}

```{r digits_secs_tbl}
options(digits.secs = 3)
dplyr::as_tibble(df)
```

::: 

:::: 



## Time (data) is not your friend

- Time zones are hell

```{r tz}
lubridate::tz(df$time)
```

- `read.gt3x` attached a GMT timezone to the data, but there is a note

```{r gt3x_note, echo = FALSE}
knitr::include_graphics(here::here("images/read.gt3x_note.png"))
```

- "local" means local to the device/initialization, not your machine

Can do `tz<-` to change the timezone if you want (watch out for DST):

```{r, eval=FALSE}
tz(df$time) = "EST"
```


## Header - in the attributes

The format of `df` is a `activity_df`, which is why you see the header information, but you need to know how to extract these:

:::: {.columns}

::: {.column width="50%"}

```{r attributes_df}
names(attributes(df))
attr(df, "sample_rate")
attr(df, "acceleration_max")
attr(df, "time_zone")
```

:::

::: {.column width="50%"}

```{r show_attr_header}
attr(df, "header")
```
:::
::::

# Important - save attributes if convert to `data.frame`/`tibble`

## Zeroes

- Again, these zeroes are not "real" zeroes

```{r zeroes}
library(dplyr)
df %>% filter(X == 0, Y == 0, Z == 0)
```

## Fill Zeros - using LOCF

:::: {.columns}

::: {.column width="50%"}

- Fill these in using last observation carried forward (LOCF)
- What ActiLife does
- Respects a zero variance for previous values

:::

::: {.column width="50%"}

```{r fill_data}
sample_rate = attr(df, "sample_rate")
acceleration_max = as.numeric(attr(df, "acceleration_max"))
df_zeros = df = dplyr::as_tibble(df)
df = df %>% 
  # find where all zeroes/imputed zeroes
  mutate(all_zero = X == 0 & Y == 0 & Z == 0) %>% 
  # replace all 0 with NA so it can be filled  
  mutate(
    X = ifelse(all_zero, NA_real_, X),
    Y = ifelse(all_zero, NA_real_, Y),
    Z = ifelse(all_zero, NA_real_, Z)
  )
df = df %>% 
  # last observation carried forward
  tidyr::fill(X, Y, Z, .direction = "down")
```


```{r fill_data_show_head}
#| echo: false
head(
  df %>% filter(
    all_zero | 
      dplyr::lead(all_zero, default = FALSE) | 
      dplyr::lead(all_zero, n = 2, default = FALSE)
  )
)
```



:::
::::

```{r remove, echo=FALSE}
df = df %>% 
  select(-all_zero)
```

# Can now create summaries/metrics, but ...

# Visualization

# If you plot less with more data, something is going in the wrong direction <br>- Karl Broman

## Reshaping Raw Data for `ggplot2`

:::: {.columns}

::: {.column width="50%"}

Reshape the data by Axis: 
```{r reshape_data_for_plot_long}
long = df %>% 
  tidyr::pivot_longer(cols = c(X, Y, Z), 
                      names_to = "axis", 
                      values_to = "acceleration")
head(long)
```
:::


::: {.column width="50%"}

Lots of data:

```{r reshape_data_for_plot_long_lot}
nrow(long)
long %>% 
  count(axis)
```

:::

::::

## Plot First 5 minutes (30Hz dense)

```{r quickplot}
library(ggplot2); library(lubridate)
(qp = long %>% 
    filter(between(time, floor_date(time[1]), 
                   floor_date(time[1]) + as.period(5, "minutes"))) %>% 
    ggplot(aes(x = time, y = acceleration, colour = axis)) + 
    geom_rect(aes(xmin = ymd_hms("2017-10-30 15:00:22"),
                  xmax = ymd_hms("2017-10-30 15:00:37"),
                  ymin = -Inf, ymax = Inf), fill = 'pink', alpha = 0.05) + 
    geom_line())
```


## Same Plot with Zeroes

```{r quickplot2, echo = FALSE}
(qp_zeros = df_zeros %>% 
   tidyr::pivot_longer(cols = c(X, Y, Z), 
                       names_to = "axis", 
                       values_to = "acceleration") %>% 
   filter(between(time, floor_date(time[1]), 
                  floor_date(time[1]) + as.period(5, "minutes"))) %>% 
   ggplot(aes(x = time, y = acceleration, colour = axis)) + 
   geom_rect(aes(xmin = ymd_hms("2017-10-30 15:00:22"),
                 xmax = ymd_hms("2017-10-30 15:00:37"),
                 ymin = -Inf, ymax = Inf), fill = 'pink', alpha = 0.05) + 
   geom_line())
```

## Plot all data

- Creating separate `date` and `time` useful for plotting/summary

```{r long_create_hourtime, eval = FALSE}
(long = long %>% 
   mutate(date = as_date(time),
          hourtime = hms::as_hms(time)))
```
```{r long_create_hourtime_show, eval = TRUE, echo = FALSE}
(long %>% 
   head(10) %>% 
   mutate(date = as_date(time),
          hourtime = hms::as_hms(time)))
```


##  Plot all data

:::: {.columns}

::: {.column width="40%"}
- Has to plot `r nrow(long)` points (takes a long time)

```{r run_bigplot, eval = FALSE}
long %>% 
  ggplot(aes(x = hourtime, 
             y = acceleration, 
             colour = axis)) + 
  facet_wrap(~ date, ncol = 1) + 
  geom_step()
```
:::



::: {.column width="60%"}

```{r show_bigplot, out.height="25%"}
#| echo: false
knitr::include_graphics(here::here("images/bigplot.png"))
```

:::
::::


##  Plot Second-Level Data 

Take average over each axis and plot

:::: {.columns}

::: {.column width="40%"}


```{r run_second_bigplot, eval = FALSE}
long %>% 
  mutate(time = floor_date(time, unit = "1 second")) %>% 
  group_by(time, axis) %>%
  summarise(
    acceleration = mean(acceleration, na.rm = TRUE), .groups = "drop"
  ) %>% 
  mutate(date = as_date(time),
         hourtime = hms::as_hms(time)) %>% 
  ggplot(aes(x = hourtime, 
             y = acceleration, 
             colour = axis)) + 
  facet_wrap(~ date, ncol = 2) + 
  geom_step() + 
  theme(text = element_text(size = 15)) + 
  guides(colour = guide_legend(position = "bottom"))
```

:::


::: {.column width="60%"}

```{r run_second_bigplot_show}
#| fig-height: 10
#| fig-width: 10
#| echo: false
#| dependson: run_second_bigplot
<<run_second_bigplot>>
```

:::
::::


## Gravity Correction/Calibration 

Gravity correction [@gravity] or gravity calibration: try to correct data that is miscalibrated
- estimates scale and shift parameters fitting to unit sphere

**Note: Not all pipelines employ this, including a number of pipelines for ActiGraph data.**

- Estimating how much of the data is projected onto the unit sphere (radius of length 1 for all 3 axes). 
- Filters values standard deviation of the signal was <13 m$g$ (milli-$g$) in all three axes within a 10-second time window.    
- Iterative weighted least squares to get scale/shift parameter

## Gravity Correction/Calibration 

The `GGIR::g.calibrate` function takes in a data filename and calculates the calibration parameters.  It is typically useful to input the output of `g.inspectfile` that provides metadata and a specification of the file being calibrated.  

```{r g_calibrate}
library(GGIR)
info = g.inspectfile(gt3x_file)
calibration_params = g.calibrate(
  datafile = gt3x_file, 
  inspectfileobject = info)
```

```{r calibrate_cal_estimates}
calibration_params[c("scale", "offset")]
```

```{r df_calibrated}
df_calibrated = df
df_calibrated[, c("X", "Y", "Z")] = scale(
  df[, c("X", "Y", "Z")], 
  center = -calibration_params$offset, 
  scale = 1/calibration_params$scale)
```

## Idle Sleep Mode & Gravity Correction
In the `GGIR` code [g.calibrate calls g.readaccfile](https://github.com/wadpac/GGIR/blob/9c7e794de27380b801451a2d889e6d4ca0677313/R/g.calibrate.R#L105) and if we look deeper, it [reads in the data using `read.gt3x::read.gt3x`](https://github.com/wadpac/GGIR/blob/9c7e794de27380b801451a2d889e6d4ca0677313/R/g.readaccfile.R#L275), **but with the default of `imputeZeroes = FALSE`**.  That means that the calibration does not use any idle sleep mode data for estimation.  

Thus, if we have read in the data and performed operations and then want to perform gravity calibration, we have a few options:

1) Estimate gravity correction parameters separately and then apply to data (recommended).
2) Output the data to a format GGIR understands and have it estimate gravity correction parameters from that data.
3) Pass the data to `agcounts::agcalibrate`.
We recommend not using imputed zeroes, or fixed zeroes to estimate calibration parameters as it may bias the calibration parameters. 

# We're not using calibrated data

## Creating Activity Counts {#sec-create-ac-nonwear}

- [agcounts](https://github.com/bhelsel/agcounts) package implements method from https://github.com/actigraph/agcounts described in @neishabouri2022quantification

```{r run_ac60}
ac60 = df %>% 
  agcounts::calculate_counts(epoch = 60L, tz = lubridate::tz(df$time))
ac60 = ac60 %>% 
  select(time, AC = Vector.Magnitude, everything())
head(ac60)
```

- [actilifecounts](https://cran.r-project.org/web/packages/actilifecounts/index.html) another implementation
- https://github.com/jhuwit/agcounter - another implementation using `reticulate`


## Plotting Activity Counts


```{r plot_ac60_show}
#| eval: false
ac60 %>% 
  mutate(date = lubridate::as_date(time),
         hourtime = hms::as_hms(time)) %>% 
  ggplot(aes(x = hourtime, y = AC)) + 
  geom_step() +
  facet_wrap(~ date, ncol = 1)  
```

```{r plot_ac60}
#| dependson: plot_ac60_show
#| echo: false
#| out-width: "100%"
<<plot_ac60_show>>
```


## Non-wear Detection

Two of the most popular methods [@CHOI2011; @troiano2014evolution] are based on ActiGraph activity counts and have a specified window for finding zero counts with some flexibility of having spikes minutes of wear.  These methods will be referred to as the Choi [@CHOI2011] and Troiano [@troiano2014evolution] methods.  

From @knaier2019validation, they describe:

>  "Troiano" defines non-wear time as intervals of at least 60 consecutive minutes of zero activity counts, allowing for up to two consecutive minutes of counts between 1 and 100 counts. The algorithm "Choi" defines non-wear times as periods of consecutive 0-counts of a certain duration. This duration is defined as âminimum length of non-wear timesâ. The default setting by the manufacturer is 90 min. 


These methods have been implemented in the `actigraph.sleepr` package.  

## Estimating Non-wear Minutes

Rename the `time` column to `timestamp` and replace the columns with their lowercase counterpart for `actigraph.sleepr`:


```{r choi_data}
data = ac60 %>%
  rename(timestamp = time,
         axis1 = Axis1,
         axis2 = Axis2,
         axis3 = Axis3)
```

Need workaround to cast the timestamp as a `double` so the checks pass for no gaps:

```{r choi_check2}
mode(data$timestamp) = "double"
actigraph.sleepr::has_missing_epochs(data)
```


```{r choi}
choi_nonwear = actigraph.sleepr::apply_choi(data, use_magnitude = TRUE)
head(choi_nonwear)
```

## Estimating Non-wear Minutes

- We can transform this to be seconds instead of current bout format:

```{r}
choi_df = purrr::map2_df(
  choi_nonwear$period_start, choi_nonwear$period_end,
  function(from, to) {
    data.frame(timestamp = seq(from, to, by = 60L),
               choi_wear = FALSE)
  })
data = left_join(data, choi_df) %>%
  tidyr::replace_na(list(choi_wear = TRUE))
head(data)
data %>% 
  count(choi_wear)
```


## Plotting Non-wear


Overall, this looks like relatively clean data, but there are some segments (e.g. 2017-11-01 at 20:00) that may be misclassified.

```{r choi_plot}
#| fig-height: 10
#| fig-width: 12
plot_data = data %>% 
  rename(time = timestamp) %>% 
  mutate(date = lubridate::as_date(time),
         hourtime = hms::as_hms(time)) %>% 
  ggplot(aes(x = time, y = AC)) + 
  geom_segment(
    aes(x = time, xend = time,
        y = -Inf, yend = Inf, color = choi_wear), alpha = 0.25) + 
  geom_line() +
  facet_wrap(~ date, ncol = 1)
```



## MIMS Units 

:::: {.columns}

::: {.column width="50%"}

[`MIMSunit`](https://github.com/mhealthgroup/mimsunit) package - calculate Monitor-Independent Movement Summary unit [@mims]:

 - interpolation of the signal to 100Hz, 
 - extrapolate signal for regions that have hit the maximum/minimum acceleration units for the device
 - band-pass filter from 0.2 to 5Hz,
 - absolute value of the area under the curve (AUC) using a trapezoidal rule, 
 - truncates low signal values to $0$.

:::

::: {.column width="50%"}
You may need to rename the `time` column to `HEADER_TIME_STAMP` for MIMS units depending on the version of the package:

```{r calculate_mims}
#| eval: false
dynamic_range = c(-acceleration_max, acceleration_max)
mims = df %>% 
  rename(HEADER_TIME_STAMP = time) %>% 
  MIMSunit::mims_unit(dynamic_range = dynamic_range, epoch = "1 min")
```

```{r calculate_mims_load}
#| echo: false
mims = readr::read_rds(here::here("data/mims.rds"))
head(mims)
```

```{r plot_mims}
#| echo: false
mims %>% 
  ggplot(aes(x = MIMS_UNIT)) + geom_histogram() + xlab("MIMS (per minute)")
```

:::
:::: 

## Compare MIMS and AC 

@karas2022comparison found a correlation of $\geq 0.97$ between AC and MIMS units.  

```{r}
joined = ac60 %>% 
  full_join(mims %>% 
              rename(time = HEADER_TIME_STAMP))
cor(joined$AC, joined$MIMS_UNIT)
joined %>% 
  ggplot(aes(x = MIMS_UNIT, y = AC)) + geom_point() + geom_smooth(se = FALSE)
```


## Step Counts

Open source method for estimating stepcounts: https://github.com/OxWearables/stepcount [@stepcount], ported using `reticulate`. 

Must load module and then run (can use GPU):

```{r code_stepcount}
#| eval: false
stepcount::unset_reticulate_python()
stepcount::use_stepcount_condaenv()
sc = stepcount::stepcount(df, sample_rate = sample_rate, model_type = "ssl")
```

```{r get_stepcount}
#| echo: false
sc = readr::read_rds(here::here("data/stepcount.rds"))
```

If no model is specified, the model is downloaded to a temporary directory, but users can use the `stepcount::sc_download_model` function to download the model file, store it, and pass it via the `model_path` argument. 

## Step Counts

:::: {.columns}

::: {.column width="50%"}

The output of `stepcount` is a list of different pieces of information, including information about the device:

```{r stepcount_output}
names(sc)
```

A `data.frame` of flags for walking:

```{r stepcount_walking}
head(sc$walking)
```


:::

::: {.column width="50%"}

The main output of interest: `data.frame` of estimated steps:

```{r stepcount_steps}
head(sc$steps)
```

```{r plot_steps}
#| echo: false
sc$steps %>% 
  ggplot(aes(x = steps)) + geom_histogram() + xlab("Number of Steps in 10s")
```

:::
::::

## Step Counts Aggregation

The `stepcount` method estimates steps in 10-second windows, which we can aggregate into minutes:

```{r sc_steps_minute}
sc60 = sc$steps %>% 
  mutate(time = floor_date(time, "1 minute")) %>% 
  group_by(time) %>% 
  summarise(steps = sum(steps), .groups = "drop")
head(sc60)
```

## Steps Per Minute


```{r plot_sc60_show}
#| eval: false
sc60 %>% 
  mutate(date = lubridate::as_date(time),
         hourtime = hms::as_hms(time)) %>% 
  ggplot(aes(x = hourtime, y = steps)) + 
  geom_step() +
  facet_wrap(~ date, ncol = 1)
```


```{r plot_sc60}
#| dependson: plot_sc60_show
#| echo: false
#| out-width: "100%"
<<plot_sc60_show>>
```


## Steps vs AC

:::: {.columns}

::: {.column width="50%"}


```{r plot_ac60_2}
#| dependson: plot_ac60_show
#| echo: false
#| out-width: "100%"
#| fig-height: 10
#| fig-width: 5
<<plot_ac60_show>>
```

:::

::: {.column width="50%"}


```{r plot_sc60_2}
#| dependson: plot_sc60_show
#| echo: false
#| out-width: "100%"
#| fig-height: 10
#| fig-width: 5
<<plot_sc60_show>>
```

:::
::::

## Conclusions

- Can go from Raw Data to Counts/Steps
- Wear time can be done using counts even if not using them (doesn't catch everything)
- Need better quick plots for 1000s of participants
- A number of other metrics exist
- Can embarrassingly parallelize the processing
- We give NHANES derivatives

## Not Discussed

- GGIR
- MVPA/Thresholds
- Sedentary time
- Sleep estimation
- Population analysis/Lasagna plots

# References
